
---
title: "Untitled"
author: "modeloregresiónensayo"
date: "1/1/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("dplyr")
install.packages("corrplot")
install.packages("kableExtra")
install.packages("gridExtra")
install.packages("gamlass")
install.packages("caret")
install.packages("glmnet")
```



```{r warning=F, message=F, results='hide'}

library(tidyverse)
library(kableExtra)
require(gridExtra)
library(gamlss)
library(ggplot2)
library(corrplot)
library(dplyr)
library(caret)
```

# Base de datos

```{r}
datos<-readRDS("C:/Users/Pilar/Downloads/BaseFinal.rds")
db2018<-readRDS("C:/Users/Pilar/Downloads/db_2018.rds")

```


```{r}
train<-filter(datos, year<= 2016)
test <-filter(datos, year> 2016 )
testfinal= filter(datos[1831:2014,]) ## primer semestre del 2017


db2018 <- cbind(db2018,Unidades=c(0))
testmitad2018= filter(db2018[1:181,]) ## primer semestre del 2018

```


# Modelo Lineal

```{r}
mod0 <- lm(Unidades ~. , data = train)
```

## Datos atípicos

```{r out.width="60%"}
P1 <- ggplot(train, aes(y=Unidades))+
  geom_boxplot(fill='#FFCCC1',alpha=0.7)+
  labs(title = 'Gráfico de cajas para la variable Unidad',
       x = 'Unidades', y='Número de registros diarios RUNT',
       color=NULL)
cooksd <- cooks.distance(mod0)
P2<- ggplot(train, aes(x=Unidades, y=cooksd)) + 
  geom_point(col='black', fill='blue', shape=21, alpha=0.5)+ geom_hline(yintercept = 4*mean(cooksd, na.rm=T), color = "red")+ ggtitle("Distancias de Cook (Modelo Lineal")
grid.arrange(P1, P2, ncol=2)
```

```{r}
influential <- na.omit(as.numeric(names(cooksd)[(cooksd > (4/nrow(train)))]))
train2 <- datos[-influential, ]
```

# Modelo Lineal

```{r}
mod1 <- lm(Unidades ~. , data = train2)
summary(mod1)


```

## modelo seleccion hacia adelante
```{r}
mod3 <- step(mod1, direction = "forward",trace=1) 
summary(mod3)


train.R2.mod3<- summary(mod3)$r.squared
train.MSE.mod3= mean((train2$Unidades - fitted(mod3))^2)







```

## modelo selección hacia atrás
```{r}
mod4 <- step(mod1, direction = "backward",trace=1) 
summary(mod4)


train.R2.mod4<- summary(mod4)$r.squared
train.MSE.mod4= mean((train2$Unidades - fitted(mod4))^2)

```







##Modelo regresión lasso para el modelo ridge alpha =0, el mismo código



```{r}
library(glmnet)
```

```{r}
x_train <- model.matrix(Unidades~., data = train2)[, -1]

y_train <- train2$Unidades

x_testfinal <- model.matrix(Unidades~., data = testfinal)[, -1]
x_testmitad2018 <- model.matrix(Unidades~., data = testmitad2018)[, -1]
x_test <- model.matrix(Unidades~., data = test)[, -1]

x_db2018 <- model.matrix(Unidades~., data = db2018)[, -1]

```

```{r}
mod5=glmnet(x_train,y_train,alpha =1)
dim(coef(mod5))

```


```{r}
#Mejor lambda con validación cruzada 
sal.cv=cv.glmnet(x_train,y_train,alpha =1, nfolds = 10,
              type.measure = "mse",
              standardize  = TRUE
           )

plot(sal.cv)
mejor.lambda =sal.cv$lambda.min
mejor.lambda
log(mejor.lambda)

paste("Mejor valor de lambda encontrado:", sal.cv$lambda.min)

## se entrena de nuevo el modelo con el mejor lambda

mod5=glmnet(x_train,y_train,alpha =1,lambda = sal.cv$lambda.min, standardize = TRUE)

coef(mod5)[,which(mod5$lambda==mejor.lambda)]

## predicciones de train

predicciones_train <- predict(mod5, newx = x_train)


## medidas de train

train.MSE.mod5 <- mean((predicciones_train - y_train)^2)
train.R2.mod5 = R2(predicciones_train,y_train)





```


```{r}
df_coeficientes <- coef(sal.cv) %>%
                   as.matrix() %>%
                   as_tibble(rownames = "predictor") %>%
                   rename(coeficiente = s1)



```

## predictores que eligio el modelo ( no me corre bien!!!)
```{r}
df_coeficientes %>%
  filter(
    predictor != "(Intercept)",
    coeficiente != 0
)  




```

## modelo ridge









```{r}

mod6=glmnet(x_train,y_train,alpha =0)
dim(coef(mod6))

#Mejor lambda con validación cruzada 
sl.cv=cv.glmnet(x_train,y_train,alpha =0, nfolds = 10,
              type.measure = "mse",
              standardize  = TRUE
           )

plot(sl.cv)
mejor.lambda2 =sl.cv$lambda.min
mejor.lambda2
log(mejor.lambda2)

paste("Mejor valor de lambda encontrado:", sl.cv$lambda.min)

## se entrena de nuevo el modelo con el mejor lambda

mod6=glmnet(x_train,y_train,alpha =0,lambda = sl.cv$lambda.min, standardize = TRUE)

coef(mod6)[,which(mod6$lambda==mejor.lambda2)]

## predicciones de train

predicciones_train6 <- predict(mod6, newx = x_train)


## medidas de train

train.MSE.mod6 <- mean((predicciones_train6 - y_train)^2)
train.R2.mod6 = R2(predicciones_train6,y_train)





```


```{r}
df_coeficientes2 <- coef(sl.cv) %>%
                   as.matrix() %>%
                   as_tibble(rownames = "predictor") %>%
                   rename(coeficiente = s1)



```

## predictores que eligio el modelo ( no me corre bien!!!)
```{r}
df_coeficientes2 %>%
  filter(
    predictor != "(Intercept)",
    coeficiente != 0
)  




```











## Medidas de  para primer semestre de 2017  para el ensayo, no el del 2018 ojo

```{r}
pred3<- predict(mod3, newdata = testfinal[,-2])
pred4<- predict(mod4, newdata = testfinal[,-2])
pred5=predict(mod5, s=mejor.lambda,newx = x_testfinal)
pred5
pred6=predict(mod6, s=mejor.lambda2,newx = x_testfinal)
pred6
r2_test_mod3 = R2(pred3,testfinal$Unidades)
r2_test_mod4= R2(pred4,testfinal$Unidades)
r2_test_mod5= R2(pred5,testfinal$Unidades)
r2_test_mod6= R2(pred6,testfinal$Unidades)

## Calculando el Pseudocoeficiente de determinación.
numerador <- (testfinal$Unidades-pred3)^2
denominador <- (testfinal$Unidades - mean(testfinal$Unidades))^2
PseudoR2_3 <-1 - (sum(numerador)/sum(denominador))
numerador <- (testfinal$Unidades-pred4)^2
PseudoR2_4 <-1 - (sum(numerador)/sum(denominador))
numerador <- (testfinal$Unidades-pred5)^2
PseudoR2_5 <-1 - (sum(numerador)/sum(denominador))
metricas_test <- data.frame("Modelo"=c("Modelo3","Modelo4","Modelo5","Modelo 6"),
                      "MSE"=c(mean((testfinal$Unidades - (pred3))^2),
                              mean((testfinal$Unidades - (pred4))^2),
                              mean((testfinal$Unidades - (pred5))^2),
                              mean((testfinal$Unidades - (pred6))^2)),
                              
                      "R pseudo2"= c(r2_test_mod3,r2_test_mod4,r2_test_mod5,r2_test_mod6))
metricas_test %>% kbl() %>%  kable_styling(font_size = 12)
```









# datos primer semestre de 2017 validación  (un ensayo)

```{r}

pred_3<- predict(mod3, newdata = testfinal)

pred_4<- predict(mod4, newdata = testfinal)

pred_5=predict(mod5, s=mejor.lambda,newx = x_testfinal)



tres0=data.frame(RMSE=RMSE(pred_3,testfinal$Unidades),Rsquare = R2(pred_3,testfinal$Unidades))

tres1=data.frame(RMSE=RMSE(pred_4,testfinal$Unidades),Rsquare = R2(pred_4,testfinal$Unidades))

tres2=data.frame(RMSE=RMSE(pred_5,testfinal$Unidades),Rsquare = R2(pred_5,testfinal$Unidades))



```



## Predicción primer semestre 2018
```{r}


predx<- predict(mod3, newdata = testmitad2018)

predy<- predict(mod4, newdata = testmitad2018)

predz=predict(mod5, s=mejor.lambda,newx = x_testmitad2018)

predW=predict(mod6, s=mejor.lambda,newx = x_testmitad2018)

```

## Predicción para todo el  2018

```{r}

pred_x<- predict(mod3, newdata = db2018)

pred_y<- predict(mod4, newdata = db2018)

pred_z=predict(mod5, s=mejor.lambda,newx = x_db2018)

pred_W=predict(mod6, s=mejor.lambda,newx = x_db2018)

```



## comparación medidas de train


```{r}
modelo <- c("Forward","Backward" ,"Ridge regression", "Lasso")
train.MSE <- c(train.MSE.mod3, train.MSE.mod4, train.MSE.mod5, train.MSE.mod6)
train.R2 <- c(train.R2.mod3, train.R2.mod4, train.R2.mod5, train.R2.mod6)
comparacion_train <- data.frame(modelo, train.MSE, train.R2)
comparacion_train
```



## comparación medidas de test


```{r}
modelo <- c("Forward","Backward" ,"Ridge regression", "Lasso")
test.MSE <- c(test.MSE.mod3, test.MSE.mod4, test.MSE.mod5,test.MSE.mod6)
test.R2 <- c(test.R2.mod3, test.R2.mod4, test.R2.mod5, test.R2.mod6)

comparacion_test <- data.frame(modelo, test.MSE, test.R2 )
comparacion_test
```

